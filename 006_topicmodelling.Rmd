# Topic Modelling

```{r}
load("./data/dtms.Rdata")
```

# Initial DTM

14 topics as per previous clustering on intial dtm
```{r}
p_ldaOut <- LDA(p_dtm,14, method="Gibbs", control=
              list(nstart=10, seed = sample.int(10000,10), best=TRUE, burnin = 1000, iter = 2000, thin=500))


topics(p_ldaOut)
ldaOut.topics <-as.matrix(topics(p_ldaOut))
terms(p_ldaOut,8)
ldaOut.terms <- as.matrix(terms(p_ldaOut,8))
#Find probabilities associated with each topic assignment
topicProbabilities <- as.data.frame(p_ldaOut@gamma) 

#no articles assigned to topic 10
```


## Refined DTM
previous analysis identified values 2-5 groups as likely, 2 being identied once in the weakest group, 3 twice, 4 twice and 5 3 times, both 4 and 5 in LSA which showed the strongest likehood of finding structure

### 4 topics
```{r}
f_ldaOut4 <- LDA(dtmf,4, method="Gibbs", control=
              list(nstart=10, seed = sample.int(10000,10), best=TRUE, burnin = 1000, iter = 2000, thin=500))


topics(f_ldaOut4)
f_ldaOut.topics4 <-as.matrix(topics(f_ldaOut4))
terms(f_ldaOut4,20)
f_ldaOut.terms4 <- as.matrix(terms(f_ldaOut4,8))
#Find probabilities associated with each topic assignment
f_topicProbabilities4 <- as.data.frame(f_ldaOut4@gamma)

```

```{r}
#https://stackoverflow.com/questions/7421503/how-to-plot-a-confusion-matrix-using-heatmaps-in-r
names(f_topicProbabilities4) <- c("Topic_1", "Topic_2", "Topic_3", "Topic_4")

ftp4 <- f_topicProbabilities4 %>% 
  rownames_to_column() %>% 
  mutate(rowname = paste("Doc", rowname, sep = "")) %>% 
  gather(x, value, 2:5) %>%
  mutate(x = factor(x), # alphabetical order by default
         y = factor(rowname, levels = rev(unique(rowname)))) # force reverse alphabetical order

ggplot(ftp4, aes(x = x, y = y, fill = value*100)) + geom_tile() + theme_classic() + geom_text(aes(label=round(value*100,0)), color="black")+ guides(fill=F) + scale_fill_gradient(low="white", high="#41cd61") + xlab("Topic") + ylab("Document") + ggtitle("Topic Assignment Probabilties")

```
### 4 topic themes
```{r}

f_ldaOut.terms4 <- as.matrix(terms(f_ldaOut4,15))
f_ldaOut.terms4[,1:4] <- stemCompletion(f_ldaOut.terms4[,1:4], icorpus, type = "prevalent")
wordcloud(f_ldaOut.terms4[,1],rep.int(1, 15), max.words=10, colors=c("#ff00f9", "#f08025", "#ffffff", "#41cd61"))

wordcloud(f_ldaOut.terms4[,2],rep.int(1, 15), max.words=10, colors=c("#ff00f9", "#f08025", "#ffffff", "#41cd61"))

wordcloud(f_ldaOut.terms4[,3],rep.int(1, 15), max.words=10, colors=c("#ff00f9", "#f08025", "#ffffff", "#41cd61"))

wordcloud(f_ldaOut.terms4[,4],rep.int(1, 15), max.words=10, colors=c("#ff00f9", "#f08025", "#ffffff", "#41cd61"))


```

### 5 topics
```{r}
# 4 clusters as identified earlier
f_ldaOut5 <- LDA(dtmf,5, method="Gibbs", control=
              list(nstart=10, seed = sample.int(10000,10), best=TRUE, burnin = 1000, iter = 2000, thin=500))


topics(f_ldaOut5)
f_ldaOut.topics5 <-as.matrix(topics(f_ldaOut5))
terms(f_ldaOut5,20)
f_ldaOut.terms5 <- as.matrix(terms(f_ldaOut5,8))
#Find probabilities associated with each topic assignment
f_topicProbabilities5 <- as.data.frame(f_ldaOut5@gamma)
```

clearer deliniation between topics with 5 by probability

```{r}
lda4_topics <- as.data.frame(f_ldaOut.topics4) %>% 
  rownames_to_column() %>% 
  remove_rownames()
names(lda4_topics)[2] <- "lda4topic"

lda5_topics <- as.data.frame(f_ldaOut.topics5) %>% 
  rownames_to_column() %>% 
  remove_rownames()
names(lda5_topics)[2] <- "lda5topic"

lda_group <- merge(lda4_topics, lda5_topics, by = "rowname")
```

## CTM
```{r}
f_ctmOut <- CTM(dtmf, 4, method="VEM", control=
              list(nstart=10, seed = sample.int(10000,10), best=TRUE))

terms(f_ctmOut,8)
```


```{r}
#saveRDS(lda_group, "./data/lda_group.RDS")
```

```{r}
# https://cran.r-project.org/web/packages/ldatuning/vignettes/topics.html

result_lda <- FindTopicsNumber(
  dtmf,
  topics = seq(from = 2, to = 30, by = 1),
  metrics = c("Griffiths2004", "CaoJuan2009", "Arun2010", "Deveaud2014"),
  method = "Gibbs",
  control = list(seed = 77),
  mc.cores = 4L,
  verbose = TRUE
)

FindTopicsNumber_plot(result_lda)
```


```{r}
# https://cran.r-project.org/web/packages/textmineR/vignettes/c_topic_modeling.html

docs_ser <- readRDS("./data/docs_searched.RDS")
final_stopwords <- readRDS("./data/finalstops.RDS")
d_name <- lapply(docs_ser, function(x) x <- x$doc)
d_name <- unlist(d_name)
d_vec <- lapply(docs_ser, function(x) x <- x$content)
d_vec <- unlist(d_vec)

tmr_dtmf <- CreateDtm(doc_vec = d_vec, # character vector of documents
                 doc_names = d_name, # document names
                 ngram_window = c(1, 3), # minimum and maximum n-gram length
                 stopword_vec = c(stopwords::stopwords("en"), # stopwords from tm
                                  stopwords::stopwords(source = "smart"),
                                  final_stopwords), # this is the default value
                 lower = TRUE, # lowercase - this is the default value
                 remove_punctuation = TRUE, # punctuation - this is the default
                 remove_numbers = TRUE, # numbers - this is the default
                 verbose = TRUE, # Turn off status bar for this demo
                 cpus = 4) # default is all available cpus on the system

tmr_lda <- FitLdaModel(dtm = tmr_dtmf, 
                     k = 4,
                     iterations = 500, # I usually recommend at least 500 iterations or more
                     burnin = 180,
                     alpha = 0.1,
                     beta = 0.05,
                     optimize_alpha = TRUE,
                     calc_likelihood = TRUE,
                     calc_coherence = TRUE,
                     calc_r2 = TRUE,
                     cpus = 4) 

plot(tmr_lda$log_likelihood, type = "l")

hist(tmr_lda$coherence, 
     col= "blue", 
     main = "Histogram of probabilistic coherence")

tmr_lda$top_terms <- GetTopTerms(phi = tmr_lda$phi, M = 5)
head(t(tmr_lda$top_terms))

tmr_lda$prevalence <- colSums(tmr_lda$theta) / sum(tmr_lda$theta) * 100

plot(tmr_lda$prevalence, tmr_lda$alpha, xlab = "prevalence", ylab = "alpha")

tmr_lda$labels <- LabelTopics(assignments = tmr_lda$theta > 0.05, 
                            dtm = tmr_dtmf,
                            M = 1)

tmr_lda$summary <- data.frame(topic = rownames(tmr_lda$phi),
                            label = tmr_lda$labels,
                            coherence = round(tmr_lda$coherence, 3),
                            prevalence = round(tmr_lda$prevalence,3),
                            top_terms = apply(tmr_lda$top_terms, 2, function(x){
                              paste(x, collapse = ", ")
                            }),
                            stringsAsFactors = FALSE)

tmr_lda$summary[ order(tmr_lda$summary$prevalence, decreasing = TRUE) , ][ 1:10 , ]
```


```{r,  eval = FALSE}
# https://rdrr.io/github/ChengMengli/tf-idf/f/vignettes/Introduction%20to%20textmineR.Rmd

# choose a range of k 
# - here, the range runs into the corpus size. Not recommended for large corpora!
k_list <- seq(2, 61, by = 1)

# set up a temporary directory to store fit models so you get partial results
# if the process fails or times out. This is a trivial example, but with a decent
# sized corpus, the procedure can take hours or days, depending on the size of 
# the data and complexity of the model.
# I'm using the digest function to create a hash so that it's obvious this is a 
# temporary directory
model_dir <- paste0("models_", digest::digest(colnames(tmr_dtmf), algo = "sha1"))

if (!dir.exists(model_dir)) dir.create(model_dir)

# Fit a bunch of LDA models
# even on this trivial corpus, it will a bit of time to fit all of these models
model_list <- TmParallelApply(X = k_list, cpus = 4, FUN = function(k){
  filename = file.path(model_dir, paste0(k, "_topics.rda"))

  if (!file.exists(filename)) {
    m <- FitLdaModel(dtm = tmr_dtmf, k = k, iterations = 500)
    m$k <- k
    m$coherence <- CalcProbCoherence(phi = m$phi, dtm = tmr_dtmf, M = 5)
    save(m, file = filename)
  } else {
    load(filename)
  }

  m
})#, export=c("tmr_dtmf", "model_dir")) # export only needed for Windows machines

# Get average coherence for each model
coherence_mat <- data.frame(k = sapply(model_list, function(x) nrow(x$phi)), 
                            coherence = sapply(model_list, function(x) mean(x$coherence)), 
                            stringsAsFactors = FALSE)


# Plot the result
# On larger (~1,000 or greater documents) corpora, you will usually get a clear peak
plot(coherence_mat, type = "o", main = "Probabilistic Coherence", xlab = "Number of Topics", ylab = "Coherence")

# 4, 5 is ok too and 12, 20 and 38
```

### 12 topics
```{r}
f_ldaOut12 <- LDA(dtmf,12, method="Gibbs", control=
              list(nstart=10, seed = sample.int(10000,10), best=TRUE, burnin = 1000, iter = 2000, thin=500))


topics(f_ldaOut12)
f_ldaOut.topics12 <-as.matrix(topics(f_ldaOut12))
terms(f_ldaOut12,20)
f_ldaOut.terms12 <- as.matrix(terms(f_ldaOut12,20))
#Find probabilities associated with each topic assignment
f_topicProbabilities12 <- as.data.frame(f_ldaOut12@gamma)

```

### 20 topics
```{r}
f_ldaOut20 <- LDA(dtmf,20, method="Gibbs", control=
              list(nstart=10, seed = sample.int(10000,10), best=TRUE, burnin = 1000, iter = 2000, thin=500))


topics(f_ldaOut20)
f_ldaOut.topics20 <-as.matrix(topics(f_ldaOut20))
terms(f_ldaOut20,20)
f_ldaOut.terms20 <- as.matrix(terms(f_ldaOut20,20))
#Find probabilities associated with each topic assignment
f_topicProbabilities20 <- as.data.frame(f_ldaOut20@gamma)
```


### 49 topics
```{r}
f_ldaOut49 <- LDA(dtmf,49, method="Gibbs", control=
              list(nstart=10, seed = sample.int(10000,10), best=TRUE, burnin = 1000, iter = 2000, thin=500))


topics(f_ldaOut49)
f_ldaOut.topics49 <-as.matrix(topics(f_ldaOut49))
terms(f_ldaOut49,20)
f_ldaOut.terms49 <- as.matrix(terms(f_ldaOut49,20))
#Find probabilities associated with each topic assignment
f_topicProbabilities49 <- as.data.frame(f_ldaOut49@gamma)

tpn <- 1:49
tpn <- paste("Topic", tpn, sep = "_")

names(f_topicProbabilities49) <- tpn

ftp49 <- f_topicProbabilities49 %>% 
  rownames_to_column() %>% 
  mutate(rowname = paste("Doc", rowname, sep = "")) %>% 
  gather(x, value, 2:50) %>%
  mutate(x = factor(x, levels = unique(x)), # alphabetical order by default
         y = factor(rowname, levels = rev(unique(rowname)))) # force reverse alphabetical order

ggplot(ftp49, aes(x = x, y = y, fill = value*100)) + geom_tile() + theme_classic() + geom_text(aes(label=round(value*100,0)), color="black")+ guides(fill=F) + scale_fill_gradient(low="white", high="#41cd61") + xlab("Topic") + ylab("Document") + ggtitle("Topic Assignment Probabilties") + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))


f_ldaOut.terms49 <- as.matrix(terms(f_ldaOut49, 8))
f_ldaOut.terms49 <- t(f_ldaOut.terms49)
f_ldaOut.terms49[,1:5] <- stemCompletion(f_ldaOut.terms49[,1:5], icorpus, type = "prevalent")
f_ldaOut.terms49 <- as.data.frame(f_ldaOut.terms49, stringsAsFactors = FALSE)
f_ldaOut.terms49 <- f_ldaOut.terms49 %>% 
  rownames_to_column(var = "topicnum")
f_ldaOut.terms49$topic <- paste(f_ldaOut.terms49$V1, f_ldaOut.terms49$V2, f_ldaOut.terms49$V3, f_ldaOut.terms49$V4, f_ldaOut.terms49$V5, sep = ", ")
f_ldaOut.terms49$topic <- paste(f_ldaOut.terms49$topicnum, f_ldaOut.terms49$topic, sep = " - " )
f_ldaOut.terms49$topicnum <- gsub(" ", "_", f_ldaOut.terms49$topicnum)

fntopicslabel <- c("certainty", #topic1
                   "document analysis", #topic2
                   "sharing information", #topic3
                   "academic research", #topic4
                   "problem solving", #topic5
                   "statistical distributions", #topic6
                   "quantitative analysis", #topic7
                   "decision making", #topic8
                   "building understanding", #topic9
                   "sensemaking", #topic10
                   "working in teams", #topic11
                   "strategic problem solving", #topic12
                   "document similarity analysis", #topic13
                   "project success", #topic14
                   "stakeholder communication", #topic15
                   "?fundamental structure", #topic16
                   "not repeating the past", #topic17
                   "?understanding context", #topic18
                   "identifying failure", #topic19
                   "idea generation", #topic20
                   "?connections", #topic21
                   "time management", #topic22
                   "topic modelling", #topic23
                   "professional dialogues", #topic24
                   "technology for problem solving", #topic25
                   "design systems", #topic26
                   "increasing diversity", #topic27
                   "consequences of poor management practice", #topic28
                   "planning change", #topic29
                   "support vector machines", #topic30
                   "project management", #topic31
                   "process controls", #topic32
                   "error management", #topic33
                   "issues with moving too fast", #topic34
                   "issues with technique", #topic35
                   "talking about issues", #topic36
                   "data analysis and modelling", #topic37
                   "oganisations", #topic38
                   "teams", #topic39
                   "data modelling, collinearity", #topic40
                   "clustering algorithms", #topic41
                   "text mining", #topic42
                   "people management", #topic43
                   "process development", #topic44
                   "?excel", #topic45
                   "systems implementation and development", #topic46
                   "monte carlo simulation", #topic47
                   "organisation structure", #topic48
                   "risk management" #topic49
                   )

fntopicslabellist <- paste("Topic", " ",(1:49), " - ", fntopicslabel, sep = "")
fntlltogether <- paste(fntopicslabellist, collapse = ", ")

f_ldaOut.terms49$topicname <-  fntopicslabel

topic49assign <- ftp49 %>% 
  filter(value >= 0.12)
names(topic49assign)[2] <- "topicnum"

topic49assign <- merge(topic49assign, f_ldaOut.terms49, by = "topicnum")

topicnames49 <- f_ldaOut.terms49 %>% 
  select(topicnum, topicname)

ftp49 <- merge(ftp49, topicnames49, by.x = "x", by.y = "topicnum") 

ftp49 <- ftp49 %>% 
  mutate(topicname = factor(topicname)) # force reverse alphabetical order

ggplot(ftp49, aes(x = topicname, y = rowname, fill = value*100)) + geom_tile() + theme_classic() + geom_text(aes(label=round(value*100,0)), color="black")+ guides(fill=F) + scale_fill_gradient(low="white", high="#41cd61") + xlab("Topic") + ylab("Document") + ggtitle("Topic Assignment Probabilties") + theme(axis.text.x = element_text(angle = 50, hjust=1))

topicnames49

```


### NMI between topics?

```{r}
betterlsaclus <- readRDS(file = "./data/betterlsaclus.RDS")
f_ldaOut.topics4
topics4 <- as.data.frame(f_ldaOut.topics4)
names(topics4) <- "fourtopicassignments"
betterlsaclus$fourtopicassignments <- topics4$fourtopicassignments


similarity <- betterlsaclus
names(similarity)[3:6] <- c("LSA_Network_Graph", "LSA_Clusters", "LSA_Clusters2", "Topic_Model")
similarity <- similarity[,-4]
shared <- proxy::dist(similarity[,3:5], method = NMI, pairwise = TRUE, by_rows = FALSE)
shared <- as.matrix(shared)
corrplot(shared, method = "number", is.corr = FALSE)
```

